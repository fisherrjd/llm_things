### Goal

- Attempt to proxy small LLMS locally from my macbook to other devices on my network

#### Software tools

- [Open Web-UI](https://github.com/open-webui/open-webui)

- [LiteLLM](https://github.com/BerriAI/litellm)

#### Deployment Tools

- [Kubernetes](https://docs.litellm.ai/docs/proxy/deploy#advanced-deployment-settings)

### TODO

- <https://github.com/benaduggan/nix/blob/main/machines/home-server/configuration.nix>

lite llm env vars:

```
UI_USERNAME=
UI_PASSWORD=
LITELLM_MASTER_KEY=
LITELLM_SALT_KEY=
DATABASE_URL=
PORT=
STORE_MODEL_IN_DB=
ANTHROPIC_API_KEY=
OPENAI_API_KEY=
```
